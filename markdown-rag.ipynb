{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG System for CFA Curriculum (Google Colab Version)\n",
        "\n",
        "This notebook implements a full Retrieval-Augmented Generation (RAG) pipeline to create high-quality, exam-style questions and flashcards from the CFA curriculum. This version is specifically adapted for use in Google Colab.\n",
        "\n",
        "### **System Architecture**\n",
        "\n",
        "1.  **Indexing Pipeline (Offline):**\n",
        "    * **Load:** Read all `.md` files from the Colab environment.\n",
        "    * **Chunk:** Split documents into meaningful sections based on Markdown headers.\n",
        "    * **Embed & Store:** Convert text chunks into vector embeddings and store them in a `ChromaDB` vector store in the Colab runtime.\n",
        "\n",
        "2.  **Generation Pipeline (Online):**\n",
        "    * **Query:** The user specifies a Learning Outcome Statement (LOS) ID.\n",
        "    * **Retrieve:** Fetch the most relevant text chunks for that LOS from the vector store.\n",
        "    * **Generate:** Use a powerful LLM (Gemini 1.5 Pro) with a carefully engineered prompt to generate structured JSON output (MCQs or flashcards)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installations\n",
        "\n",
        "First, we install the necessary Python libraries for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q --upgrade langchain langchain_community langchain_google_vertexai google-cloud-aiplatform chromadb pydantic unstructured markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Google Cloud Authentication\n",
        "\n",
        "In Google Colab, we authenticate using the built-in `google.colab.auth` library. This will prompt you to log in to your Google account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "hY9pG5k-0F3C",
        "outputId": "f7841c6d-9659-4ac5-f481-331e9c56f8f0"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Configure Google Cloud Project\n",
        "\n",
        "Enter your Google Cloud Project ID in the form below. Then, we initialize Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "forms": {
          "PROJECT_ID": "your-gcp-project-id"
        },
        "id": "Sj_B4o-s0F3F",
        "outputId": "33ac3c48-cd01-4475-a0c5-555e094f3183"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "PROJECT_ID = \"your-gcp-project-id\"  #@param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"\n",
        "# ---------------------\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. The Indexing Pipeline\n",
        "\n",
        "This is the offline process where we prepare our knowledge base. It only needs to be run once, or whenever the underlying curriculum documents are updated.\n",
        "\n",
        "**Note on File Storage:** The files created in this section are stored in the temporary Colab runtime. They will be deleted when the runtime is disconnected. For persistent storage, you can mount your Google Drive (see next cell)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Optional) Mount Google Drive for Persistent Storage\n",
        "\n",
        "Run this cell and follow the authentication prompts to mount your Google Drive. You can then change the paths in the following cells (e.g., `curriculum_path`, `db_path`) to save your files directly to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqH8TzWb0F3I"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Example of changing paths to use Google Drive\n",
        "# curriculum_path = '/content/drive/MyDrive/cfa_curriculum_md/'\n",
        "# db_path = \"/content/drive/MyDrive/cfa_vector_db\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Load Markdown Documents\n",
        "\n",
        "First, you need to upload your curriculum files. In the Colab file browser on the left, create a folder named `cfa_curriculum_md` and upload your `.md` files into it. \n",
        "\n",
        "The cell below creates some dummy files for demonstration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2L0s26Fh0F3J",
        "outputId": "385b24c8-39e2-45e0-81f3-d09618f081d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 204/204 [00:09<00:00, 20.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 204 documents.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "# Use local Colab path by default\n",
        "curriculum_path = \"./markdown/\"\n",
        "db_path = \"./cfa_vector_db\"\n",
        "\n",
        "# Create a dummy directory and files for demonstration purposes\n",
        "# if not os.path.exists(curriculum_path):\n",
        "#     os.makedirs(curriculum_path)\n",
        "\n",
        "# dummy_content_a = \"\"\"\n",
        "# # Reading 42: Correlation and Regression\n",
        "# ## LOS 42.a: Differentiate between correlation and covariance\n",
        "# Covariance measures the directional relationship between two variables. A positive covariance means that variables move in the same direction, while a negative covariance means they move in opposite directions. The formula for population covariance is Cov(X,Y) = Σ[(Xi - μx)(Yi - μy)] / N.\n",
        "# Correlation is a standardized measure of the linear relationship between two variables. It is calculated by dividing the covariance by the product of the standard deviations of the two variables. The value of correlation is always between -1 and +1.\n",
        "# \"\"\"\n",
        "# dummy_content_b = \"\"\"\n",
        "# # Reading 42: Correlation and Regression\n",
        "# ## LOS 42.b: Explain the properties of correlation\n",
        "# The correlation coefficient has several key properties. It is a unitless measure. The correlation of a variable with itself is always 1. A correlation of 0 indicates no linear relationship, but does not rule out a non-linear one.\n",
        "# \"\"\"\n",
        "\n",
        "# with open(os.path.join(curriculum_path, \"Reading_42_LOS_a.md\"), \"w\") as f:\n",
        "#     f.write(dummy_content_a)\n",
        "# with open(os.path.join(curriculum_path, \"Reading_42_LOS_b.md\"), \"w\") as f:\n",
        "#     f.write(dummy_content_b)\n",
        "\n",
        "# Load all markdown files\n",
        "loader = DirectoryLoader(curriculum_path, glob=\"**/*.md\", show_progress=True)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"Loaded {len(docs)} documents.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Chunk Documents and Add Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "eU8Vw4z00F3L",
        "outputId": "38a9d68b-59b4-4e20-94d3-0d55e3a093ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not extract LOS from file path: markdown/LM2LOS7.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM1LOS2.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM1LOS4.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM3LOS10.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM3LOS12.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM1LOS3.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM2LOS6.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM3LOS9.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM2LOS8.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM1LOS1.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM3LOS11.pdf.md\n",
            "Warning: Could not extract LOS from file path: markdown/LM1LOS5.pdf.md\n",
            "Split 204 documents into 192 chunks.\n",
            "\n",
            "--- Example Chunk ---\n",
            "in-dex, noun (pl.in•dex.es or in•di•ces) Latin indic-, index, from indicare to indicate: an indicator, sign, or measure of something.  \n",
            "ORIGIN OF MARKET INDEXES  \n",
            "Investors had access to regularly published data on individual security prices in London as early as 1698, but nearly 200 years passed before they had access to a simple indicator to reflect security market information. To give readers a sense of how the US stock market in general performed on a given day, publishers Charles H. Dow and Edward D. Jones introduced the Dow Jones Average, the world's first security market index, in 1884. The index, which appeared in The Customers' Afternoon Letter, consisted of the stocks of nine railroads and two industrial companies. It eventually became the Dow Jones Transportation Average. Convinced that industrial companies, rather than railroads, would be \"the great speculative market\" of the future, Dow and Jones introduced a second index in May 1896-the Dow Jones Industrial Average (DJIA). It had an initial value of 40.94 and consisted of 12 stocks from major US industries. Today, investors can choose from among thousands of indexes to measure and monitor different security markets and asset classes.  \n",
            "This reading is organized as follows. Section 2 defines a security market index and explains how to calculate the price return and total return of an index for a single period and over multiple periods. Section 3 describes how indexes are constructed and managed. Section 4 discusses the use of market indexes. Sections 5, 6, and 7 discuss various types of indexes, and the final section summarizes the reading. Practice problems follow the conclusions and summary.  \n",
            "INDEX DEFINITION AND CALCULATIONS OF VALUE AND RETURNS  \n",
            "describe a security market index calculate and interpret the value, price return, and total return of an index  \n",
            "A security market index represents a given security market, market segment, or asset class. Most indexes are constructed as portfolios of marketable securities.  \n",
            "The value of an index is calculated on a regular basis using either the actual or estimated market prices of the individual securities, known as constituent securities, within the index. For each security market index, investors may encounter two versions of the same index (i.e., an index with identical constituent securities and weights): one version based on price return and one version based on total return. As the name suggests, a price return index, also known as a price index, reflects only the prices of the constituent securities within the index. A total return index, in contrast, reflects not only the prices of the constituent securities but also the reinvestment of all income received since inception.  \n",
            "At inception, the values of the price and total return versions of an index are equal. As time passes, however, the value of the total return index, which includes the reinvestment of all dividends and/or interest received, will exceed the value of the price return index by an increasing amount. A look at how the values of each version are calculated over multiple periods illustrates why.  \n",
            "The value of a price return index is calculated as:  \n",
            "$$ V_{P R I}=\\frac{\\sum_{i=1}^{N} n_{i} P_{i}}{D} $$  \n",
            "where $V_{P R I}=$ the value of the price return index $n_{i}=$ the number of units of constituent security $i$ held in the index portfolio $N=$ the number of constituent securities in the index $P_{i}=$ the unit price of constituent security $i$ $D=$ the value of the divisor The divisor is a number initially chosen at inception. It is frequently chosen so that the price index has a convenient initial value, such as 1,000 . The index provider then adjusts the value of the divisor as necessary to avoid changes in the index value that are unrelated to changes in the prices of its constituent securities. For example, when changing index constituents, the index provider may adjust the divisor so that the value of the index with the new constituents equals the value of the index prior to the changes.  \n",
            "Index return calculations, like calculations of investment portfolio returns, may measure price return or total return. Price return measures only price appreciation or percentage change in price. Total return measures price appreciation plus interest, dividends, and other distributions.  \n",
            "Calculation of Single-Period Returns  \n",
            "For a security market index, price return can be calculated in two ways: either the percentage change in value of the price return index, or the weighted average of price returns of the constituent securities. The price return of an index can be expressed as:  \n",
            "$$ \\mathrm{PR}{I}=\\frac{V{P R I 1}-V_{P R I 0}}{V_{P R I 0}} $$  \n",
            "where $\\mathrm{PR}{I}=$ the price return of the index portfolio (as a decimal number, i.e., 12 percent is 0.12 ) $V{P R I 1}=$ the value of the price return index at the end of the period $V_{P R I 0}=$ the value of the price return index at the beginning of the period Similarly, the price return of each constituent security can be expressed as:  \n",
            "$$ \\mathrm{PR}{i}=\\frac{P{i 1}-P_{i 0}}{P_{i 0}} $$  \n",
            "where  \n",
            "$$ \\begin{aligned} \\mathrm{PR}{i} & =\\text { the price return of constituent security } i \\text { (as a decimal number) } \\ P{i 1} & =\\text { the price of constituent security } i \\text { at the end of the period } \\ P_{i 0} & =\\text { the price of constituent security } i \\text { at the beginning of the period } \\end{aligned} $$  \n",
            "Because the price return of the index equals the weighted average of price returns of the individual securities, we can write:  \n",
            "$$ \\mathrm{PR}{I}=\\sum{i=1}^{N} \\mathrm{w}{i} \\mathrm{PR}{i}=\\sum_{i=1}^{N} \\mathrm{w}{i}\\left(\\frac{P{i 1}-P_{i 0}}{P_{i 0}}\\right) $$  \n",
            "where:  \n",
            "$$ \\begin{aligned} \\mathrm{PR}{I}= & \\text { the price return of index portfolio (as a decimal number) } \\ \\mathrm{PR}{i}= & \\text { the price return of constituent security } i \\text { (as a decimal number) } \\ N= & \\text { the number of individual securities in the index } \\ \\mathrm{W}{i}= & \\text { the weight of security } i \\text { (the fraction of the index portfolio allocated to } \\ & \\text { security } i) \\ P{i 1}= & \\text { the price of constituent security } i \\text { at the end of the period } \\ P_{i 0}= & \\text { the price of constituent security } i \\text { at the beginning of the period } \\end{aligned} $$  \n",
            "Equation 4 can be rewritten simply as:  \n",
            "$$ \\mathrm{PR}{I}=\\mathrm{w}{1} \\mathrm{PR}{1}+\\mathrm{w}{2} \\mathrm{PR}{2}+\\ldots+\\mathrm{w}{N} \\mathrm{PR}_{N} $$  \n",
            "where  \n",
            "$$ \\begin{aligned} \\mathrm{PR}{I}= & \\text { the price return of index portfolio (as a decimal number) } \\ \\mathrm{PR}{i}= & \\text { the price return of constituent security } i \\text { (as a decimal number) } \\ \\mathrm{W}_{i}= & \\text { the weight of security } i \\text { (the fraction of the index portfolio allocated to } \\ & \\text { security } i) \\ N= & \\text { the number of securities in the index } \\end{aligned} $$  \n",
            "Total return measures price appreciation plus interest, dividends, and other distributions. Thus, the total return of an index is the price appreciation, or change in the value of the price return index, plus income (dividends and/or interest) over the period, expressed as a percentage of the beginning value of the price return index. The total return of an index can be expressed as:  \n",
            "$$ \\mathrm{TR}{I}=\\frac{V{P R I 1}-V_{P R I 0}+I n c_{I}}{V_{P R I 0}} $$  \n",
            "where  \n",
            "$$ \\begin{aligned} \\mathrm{TR}{I}= & \\text { the total return of the index portfolio (as a decimal number) } \\ V{P R I 1}= & \\text { the value of the price return index at the end of the period } \\ V_{P R I 0}= & \\text { the value of the price return index at the beginning of the period } \\ \\mathrm{Inc}_{I}= & \\text { the total income (dividends and/or interest) from all securities in the } \\ & \\text { index held over the period } \\end{aligned} $$  \n",
            "The total return of an index can also be calculated as the weighted average of total returns of the constituent securities. The total return of each constituent security in the index is calculated as: $\\mathrm{TR}{i}=\\frac{P{1 i}-P_{0 i}+\\operatorname{In} c_{i}}{P_{0 i}}$ where $\\mathrm{TR}{i}=$ the total return of constituent security $i$ (as a decimal number) $P{1 i}=$ the price of constituent security $i$ at the end of the period $P_{0 i}=$ the price of constituent security $i$ at the beginning of the period $\\mathrm{Inc}{i}=$ the total income (dividends and/or interest) from security $i$ over the period Because the total return of an index can be calculated as the weighted average of total returns of the constituent securities, we can express total return as: $\\mathrm{TR}{I}=\\sum_{i=1}^{N} \\mathrm{w}{i} \\mathrm{TR}{i}=\\sum_{i=1}^{N} \\mathrm{w}{i}\\left(\\frac{P{1 i}-P_{0 i}+\\operatorname{Inc} c_{i}}{P_{0 i}}\\right)$ Equation 8 can be rewritten simply as $\\mathrm{TR}{I}=\\mathrm{w}{1} \\mathrm{TR}{1}+\\mathrm{w}{2} \\mathrm{TR}{2}+\\ldots+\\mathrm{w}{N} \\mathrm{TR}{N}$ where $\\mathrm{TR}{I}=$ the total return of the index portfolio (as a decimal number) $\\mathrm{TR}{i}=$ the total return of constituent security $i$ (as a decimal number) $\\mathrm{w}{i}=$ the weight of security $i$ (the fraction of the index portfolio allocated to security $i$ ) $N=$ the number of securities in the index  \n",
            "Calculation of Index Values over Multiple Time Periods  \n",
            "The calculation of index values over multiple time periods requires geometrically linking the series of index returns. With a series of price returns for an index, we can calculate the value of the price return index with the following equation:  \n",
            "$$ \\mathrm{V}{P R I T}=\\mathrm{V}{P R I 0}\\left(1+\\mathrm{PR}{I 1}\\right)\\left(1+\\mathrm{PR}{I 2}\\right) \\ldots\\left(1+\\mathrm{PR}_{I T}\\right) $$  \n",
            "where $\\mathrm{V}{\\text {PRI0 }}=$ the value of the price return index at inception $\\mathrm{V}{\\text {PRIT }}=$ the value of the price return index at time $t$ $\\mathrm{PR}_{I T}=$ the price return (as a decimal number) on the index over period $t, t=1$, $2, \\ldots, T$  \n",
            "For an index with an inception value set to 1,000 and price returns of 5 percent and 3 percent for Periods 1 and 2 respectively, the values of the price return index would be calculated as follows:  \n",
            "Period Return (\\%) Calculation Ending Value 0 1,000(1.00) 1,000.00 1 5.00 1,000(1.05) 1,050.00 2 3.00 1,000(1.05)(1.03) 1,081.50  \n",
            "Similarly, the series of total returns for an index is used to calculate the value of the total return index with the following equation:  \n",
            "$$ \\mathrm{V}{T R I T}=\\mathrm{V}{T R I 0}\\left(1+\\mathrm{TR}{I 1}\\right)\\left(1+\\mathrm{TR}{I 2}\\right) \\ldots\\left(1+\\mathrm{TR}_{I T}\\right) $$  \n",
            "where  \n",
            "$$ \\begin{aligned} \\mathrm{V}{T R I 0}= & \\text { the value of the index at inception } \\ \\mathrm{V}{T R I T}= & \\text { the value of the total return index at time } t \\ \\mathrm{TR}_{I T}= & \\text { the total return (as a decimal number) on the index over period } t, t=1,2, \\ & \\ldots, T \\end{aligned} $$  \n",
            "Suppose that the same index yields an additional 1.5 percent return from income in Period 1 and an additional 2.0 percent return from income in Period 2, bringing the total returns for Periods 1 and 2, respectively, to 6.5 percent and 5 percent. The values of the total return index would be calculated as follows:  \n",
            "Period Return (\\%) Calculation Ending Value 0 $1,000(1.00)$ $1,000.00$ 1 6.50 $1,000(1.065)$ $1,065.00$ 2 5.00 $1,000(1.065)(1.05)$ $1,118.25$  \n",
            "As illustrated above, as time passes, the value of the total return index, which includes the reinvestment of all dividends and/or interest received, exceeds the value of the price return index by an increasing amount.  \n",
            "INDEX CONSTRUCTION  \n",
            "describe the choices and issues in index construction and management compare the different weighting methods used in index construction calculate and analyze the value and return of an index given its weighting method  \n",
            "Constructing and managing a security market index is similar to constructing and managing a portfolio of securities. Index providers must decide the following:  \n",
            "Which target market should the index represent?  \n",
            "Which securities should be selected from that target market?  \n",
            "How much weight should be allocated to each security in the index?  \n",
            "When should the index be rebalanced?  \n",
            "When should the security selection and weighting decision be re-examined?\n",
            "\n",
            "--- Example Metadata ---\n",
            "{'lm_id': '40', 'los_id': '15', 'source_file': 'markdown/LM40LOS156.pdf.md'}\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "def extract_los_from_path(path):\n",
        "    \"\"\"A simple regex to pull the LOS from a filename like 'LM12LOS40.pdf.md'. Returns 'LM12LOS40'.\"\"\"\n",
        "    # Match pattern like 'LM12LOS40.pdf.md' to extract LM 12 and LOS 40\n",
        "    match = re.search(r'LM(\\d{2})LOS(\\d{2})', path, re.IGNORECASE)\n",
        "    if match:\n",
        "        return f\"{match.group(1)}:{match.group(2)}\"\n",
        "    return None\n",
        "\n",
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "]\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "\n",
        "all_chunks = []\n",
        "for doc in docs:\n",
        "    chunks = markdown_splitter.split_text(doc.page_content)\n",
        "    file_path = doc.metadata.get('source', '')\n",
        "    lm_los = extract_los_from_path(file_path)\n",
        "    # lm_los is in the format 'LM12LOS40', extract both LM and LOS\n",
        "    if lm_los is None:\n",
        "        print(f\"Warning: Could not extract LOS from file path: {file_path}\")\n",
        "        continue\n",
        "    # Assuming lm_los is in the format '12:40', we can use it directly\n",
        "    # If you need to split it further, you can do so here\n",
        "    # For example, if you want to store it as 'LM12' and 'LOS40' by splitting on ':'\n",
        "    lm_id, los_id = lm_los.split(':') if ':' in lm_los else (lm_los, None)\n",
        "\n",
        "    for chunk in chunks:\n",
        "        chunk.metadata['lm_id'] = lm_id\n",
        "        chunk.metadata['los_id'] = los_id\n",
        "        chunk.metadata['source_file'] = file_path\n",
        "        all_chunks.append(chunk)\n",
        "\n",
        "print(f\"Split {len(docs)} documents into {len(all_chunks)} chunks.\")\n",
        "print(\"\\n--- Example Chunk ---\")\n",
        "print(all_chunks[0].page_content)\n",
        "print(\"\\n--- Example Metadata ---\")\n",
        "print(all_chunks[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Embed and Store in Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eI5F9V000F3M",
        "outputId": "32131238-6f6d-49d6-9467-f3d8e578335d"
      },
      "outputs": [
        {
          "ename": "GoogleAuthError",
          "evalue": "Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/mastercfa/generator/.venv/lib/python3.13/site-packages/google/cloud/aiplatform/initializer.py:367\u001b[39m, in \u001b[36m_Config.project\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_project_as_env_var_or_google_auth_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m     project_id = \u001b[38;5;28mself\u001b[39m._project\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/mastercfa/generator/.venv/lib/python3.13/site-packages/google/cloud/aiplatform/initializer.py:114\u001b[39m, in \u001b[36m_Config._set_project_as_env_var_or_google_auth_default\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     credentials, project = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28mself\u001b[39m._credentials = \u001b[38;5;28mself\u001b[39m._credentials \u001b[38;5;129;01mor\u001b[39;00m credentials\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/mastercfa/generator/.venv/lib/python3.13/site-packages/google/auth/_default.py:685\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    683\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
            "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mGoogleAuthError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_vertexai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VertexAIEmbeddings\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m embeddings = \u001b[43mVertexAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-embedding-004\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreating and persisting vector store at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m vector_db = Chroma.from_documents(\n\u001b[32m      8\u001b[39m     documents=all_chunks,\n\u001b[32m      9\u001b[39m     embedding=embeddings,\n\u001b[32m     10\u001b[39m     persist_directory=db_path\n\u001b[32m     11\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/mastercfa/generator/.venv/lib/python3.13/site-packages/langchain_google_vertexai/embeddings.py:166\u001b[39m, in \u001b[36mVertexAIEmbeddings.__init__\u001b[39m\u001b[34m(self, model_name, project, location, request_parallelism, max_retries, credentials, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name:\n\u001b[32m    165\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m] = model_name\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_parallelism\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_parallelism\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28mself\u001b[39m.instance[\u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m, _MAX_BATCH_SIZE)\n\u001b[32m    175\u001b[39m \u001b[38;5;28mself\u001b[39m.instance[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.instance[\u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/mastercfa/generator/.venv/lib/python3.13/site-packages/langchain_google_vertexai/_base.py:155\u001b[39m, in \u001b[36m_VertexAIBase.validate_project\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    153\u001b[39m         \u001b[38;5;28mself\u001b[39m.project = \u001b[38;5;28mself\u001b[39m.credentials.project_id\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28mself\u001b[39m.project = \u001b[43minitializer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglobal_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproject\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/mastercfa/generator/.venv/lib/python3.13/site-packages/google/cloud/aiplatform/initializer.py:370\u001b[39m, in \u001b[36m_Config.project\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    368\u001b[39m     project_id = \u001b[38;5;28mself\u001b[39m._project\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GoogleAuthError(project_not_found_exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m project_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_key:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(project_not_found_exception_str)\n",
            "\u001b[31mGoogleAuthError\u001b[39m: Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project"
          ]
        }
      ],
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
        "\n",
        "print(f\"Creating and persisting vector store at: {db_path}\")\n",
        "vector_db = Chroma.from_documents(\n",
        "    documents=all_chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=db_path\n",
        ")\n",
        "print(\"Vector store created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. The Generation Pipeline\n",
        "\n",
        "Now we build the real-time part of the system. We'll load the vector store from disk and create the LangChain RAG chain to generate content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1. Load Existing Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "J1O38-pY0F3O",
        "outputId": "8741da80-b2dd-4a37-b67c-6fd9b1a52b21"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
        "vector_db_retriever = Chroma(\n",
        "    persist_directory=db_path, \n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "print(\"Vector store loaded from disk.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G8Qc7G5O0F3P",
        "outputId": "23330e23-747d-419b-a0ef-abf90b7952e5"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "MCQ_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert CFA exam question writer. Your task is to create a challenging, exam-style multiple-choice question based *only* on the provided context.\n",
        "**Instructions:**\n",
        "1. The question must directly test a key concept, formula, or definition from the context.\n",
        "2. Generate three plausible distractors (incorrect options) that represent common mistakes or misunderstandings related to the topic.\n",
        "3. The correct answer must be explicitly supported by the text.\n",
        "4. Provide a brief but clear explanation for why the correct answer is right and why the distractors are wrong, citing the context.\n",
        "5. Output the result in a single, clean JSON object. Do not include any text outside of the JSON block.\n",
        "**Context from LOS {los_id}:**\n",
        "---\n",
        "{retrieved_text}\n",
        "---\n",
        "**JSON Output Format:**\n",
        "```json\n",
        "{\n",
        "  \"question\": \"The question text...\",\n",
        "  \"options\": {\n",
        "    \"A\": \"Option A\",\n",
        "    \"B\": \"Option B\",\n",
        "    \"C\": \"Option C\"\n",
        "  },\n",
        "  \"answer\": \"B\",\n",
        "  \"explanation\": \"The correct answer is B because [...]. Option A is incorrect because [...]. Option C is incorrect because [...].\"\n",
        "}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "FLASHCARD_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert CFA content creator specializing in study aids. Your task is to create a concise and effective flashcard based *only* on the provided context.\n",
        "**Instructions:**\n",
        "1. Identify the single most important term, concept, or formula from the context. This will be the \"front\" of the flashcard.\n",
        "2. Create a clear, concise definition or explanation for the \"back\" of the flashcard.\n",
        "3. Ensure the content is directly derived from the provided text.\n",
        "4. Output the result in a single, clean JSON object. Do not include any text outside of the JSON block.\n",
        "**Context from LOS {los_id}:**\n",
        "---\n",
        "{retrieved_text}\n",
        "---\n",
        "**JSON Output Format:**\n",
        "```json\n",
        "{\n",
        "  \"front\": \"Term or Concept Name\",\n",
        "  \"back\": \"Concise definition, explanation, or formula.\"\n",
        "}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "mcq_prompt = PromptTemplate(\n",
        "    input_variables=['los_id', 'retrieved_text'],\n",
        "    template=MCQ_PROMPT_TEMPLATE\n",
        ")\n",
        "\n",
        "flashcard_prompt = PromptTemplate(\n",
        "    input_variables=['los_id', 'retrieved_text'],\n",
        "    template=FLASHCARD_PROMPT_TEMPLATE\n",
        ")\n",
        "\n",
        "print(\"Prompt templates created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3. Build the RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yI0P910j0F3Q",
        "outputId": "3b2b5f7e-c85c-44aa-ee65-72efb6d91a93"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "llm = ChatVertexAI(\n",
        "    model_name=\"gemini-1.5-pro-preview-0409\",\n",
        "    temperature=0.3,\n",
        "    generation_config={\"response_mime_type\": \"application/json\"}\n",
        ")\n",
        "\n",
        "def retrieve_context(input_dict):\n",
        "    los_id_to_query = input_dict[\"los_id\"]\n",
        "    retriever = vector_db_retriever.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\"k\": 3, \"filter\": {\"los_id\": los_id_to_query}}\n",
        "    )\n",
        "    retrieved_docs = retriever.invoke(f\"content for LOS {los_id_to_query}\")\n",
        "    retrieved_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "    return {\"retrieved_text\": retrieved_text, \"los_id\": los_id_to_query}\n",
        "\n",
        "# A parser function to safely clean and load the JSON output from the LLM\n",
        "def clean_and_parse_json(text):\n",
        "    # The model sometimes wraps the JSON in ```json ... ```, so we strip that\n",
        "    cleaned_text = text.strip().removeprefix('```json').removesuffix('```').strip()\n",
        "    return json.loads(cleaned_text)\n",
        "\n",
        "mcq_rag_chain = (\n",
        "    {\"los_id\": RunnablePassthrough()} \n",
        "    | RunnablePassthrough.assign(context=retrieve_context)\n",
        "    | (lambda x: mcq_prompt.format(\n",
        "        los_id=x[\"los_id\"],\n",
        "        retrieved_text=x[\"context\"][\"retrieved_text\"]\n",
        "      ))\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        "    | clean_and_parse_json\n",
        ")\n",
        "\n",
        "flashcard_rag_chain = (\n",
        "    {\"los_id\": RunnablePassthrough()} \n",
        "    | RunnablePassthrough.assign(context=retrieve_context)\n",
        "    | (lambda x: flashcard_prompt.format(\n",
        "        los_id=x[\"los_id\"],\n",
        "        retrieved_text=x[\"context\"][\"retrieved_text\"]\n",
        "      ))\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        "    | clean_and_parse_json\n",
        ")\n",
        "\n",
        "print(\"RAG chains are ready to be used.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Execution and Generation\n",
        "\n",
        "Let's test our system! We'll specify an LOS and run both the MCQ and Flashcard generation chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "eFpLd_5y0F3S",
        "outputId": "347209e5-9c59-4f81-a53d-2491a6157835"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# --- Specify the Target LOS ---\n",
        "target_los = \"42.a\"\n",
        "# -----------------------------\n",
        "\n",
        "print(f\"--- Generating MCQ for LOS: {target_los} ---\")\n",
        "try:\n",
        "    mcq_result = mcq_rag_chain.invoke(target_los)\n",
        "    print(json.dumps(mcq_result, indent=2))\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during MCQ generation: {e}\")\n",
        "\n",
        "print(f\"\\n--- Generating Flashcard for LOS: {target_los} ---\")\n",
        "try:\n",
        "    flashcard_result = flashcard_rag_chain.invoke(target_los)\n",
        "    print(json.dumps(flashcard_result, indent=2))\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during Flashcard generation: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Next Steps and Evaluation\n",
        "\n",
        "This notebook provides a complete, working prototype. To move this to production, consider the following:\n",
        "\n",
        "1.  **Evaluation:** Implement a \"human-in-the-loop\" review process. Generate a large batch of questions and have CFA experts review them for accuracy, relevance, and clarity. \n",
        "2.  **Prompt Iteration:** Based on feedback, refine your prompt templates. \n",
        "3.  **Chunking Strategy:** If the retrieved context is often irrelevant, experiment with different chunk sizes or `MarkdownHeaderTextSplitter` settings.\n",
        "4.  **UI/Application:** Wrap this logic in a web application using `Streamlit` or `FastAPI`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
